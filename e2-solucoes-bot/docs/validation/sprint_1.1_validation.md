# Sprint 1.1 Validation Report

**Sprint**: RAG e Base de Conhecimento
**Data**: 2025-01-12
**Status**: EM VALIDA√á√ÉO
**Objetivo**: Bot responde perguntas sobre TODOS os 5 servi√ßos com RAG funcional

---

## üìã Checklist de Valida√ß√£o

### 1. Base de Conhecimento (5 arquivos) ‚úÖ

- [x] `knowledge/servicos/energia_solar.md` - 264 linhas
- [x] `knowledge/servicos/subestacao.md` - Verificado
- [x] `knowledge/servicos/projetos_eletricos.md` - 351 linhas
- [x] `knowledge/servicos/armazenamento_energia.md` - 351 linhas
- [x] `knowledge/servicos/analise_laudos.md` - 418 linhas

**Total**: 1380+ linhas de conhecimento estruturado

### 2. Script de Ingest√£o ‚úÖ

- [x] `scripts/ingest-knowledge.sh` criado (515 linhas)
- [x] Script execut√°vel (`chmod +x`)
- [x] Valida√ß√µes implementadas:
  - [x] Depend√™ncias (curl, jq)
  - [x] Vari√°veis de ambiente (OPENAI_API_KEY, SUPABASE_URL, SUPABASE_SERVICE_KEY)
  - [x] Diret√≥rio knowledge/ existe
- [x] Chunking inteligente (500-1000 chars, overlap 100 chars)
- [x] Respeita estrutura markdown (quebra em ##)
- [x] Retry logic (3 tentativas, delay 2s)
- [x] Logging colorido (INFO/SUCCESS/WARNING/ERROR)

### 3. Fun√ß√µes Supabase ‚úÖ

- [x] `database/supabase_functions.sql` atualizado
- [x] Tabela `knowledge_documents` com schema correto:
  - [x] id TEXT (formato: category/filename/chunk-N)
  - [x] content TEXT
  - [x] embedding vector(1536)
  - [x] category VARCHAR(50)
  - [x] source_file VARCHAR(255)
  - [x] metadata JSONB
  - [x] timestamps (created_at, updated_at)
- [x] √çndices otimizados:
  - [x] ivfflat para vector search (lists=100)
  - [x] category index
  - [x] source_file index
  - [x] metadata GIN index
- [x] Fun√ß√£o `match_documents()` implementada:
  - [x] Par√¢metros: query_embedding, match_threshold (0.75), match_count (5), filter_category
  - [x] Retorna: id, content, category, source_file, metadata, similarity
  - [x] Usa cosine distance (<=>)
- [x] Fun√ß√µes de utilidade:
  - [x] delete_documents_by_category()
  - [x] delete_documents_by_source()
  - [x] get_documents_stats()
  - [x] get_category_stats()
- [x] Trigger de updated_at
- [x] Coment√°rios e queries de teste

### 4. Workflow n8n RAG ‚úÖ

- [x] `n8n/workflows/03_rag_knowledge_query.json` criado (232 linhas)
- [x] Estrutura com 7 n√≥s:
  1. [x] Webhook RAG Query (POST /webhook/rag-query)
  2. [x] Validate Input (verifica query_text)
  3. [x] Error Missing Query (resposta 400)
  4. [x] Generate Embedding (OpenAI text-embedding-3-small)
  5. [x] Query Supabase (match_documents com casting vector)
  6. [x] Format Results for AI (JavaScript formata contexto)
  7. [x] Respond Success (200 com JSON estruturado)
- [x] Conex√µes corretas entre n√≥s
- [x] Par√¢metros opcionais: category, match_threshold, match_count
- [x] Response estruturado:
  - [x] success boolean
  - [x] results array (rank, content, source, similarity, relevance)
  - [x] context string (top 3 resultados formatados para AI)
  - [x] metadata (query, total_results, avg_similarity, categories_found, files_found)

---

## üß™ Testes de Valida√ß√£o

### Teste 1: Executar Ingest Script

**Comando**:
```bash
cd /home/bruno/Desktop/Programas/E2_Solucoes/e2-solucoes-bot
./scripts/ingest-knowledge.sh
```

**Valida√ß√µes**:
- [ ] Script executa sem erros
- [ ] Processa 5 arquivos .md
- [ ] Gera chunks (estimativa: 50-100 chunks total)
- [ ] Conecta com OpenAI API
- [ ] Gera embeddings (1536 dimens√µes cada)
- [ ] Insere em Supabase knowledge_documents
- [ ] Logs mostram progresso
- [ ] Tempo de execu√ß√£o: < 5 minutos

**Resultado**: PENDENTE

---

### Teste 2: Verificar Dados no Supabase

**Query SQL**:
```sql
-- Total de documentos
SELECT COUNT(*) as total FROM knowledge_documents;

-- Por categoria
SELECT * FROM get_category_stats();

-- Por arquivo fonte
SELECT source_file, COUNT(*) as chunks
FROM knowledge_documents
GROUP BY source_file
ORDER BY chunks DESC;

-- Estat√≠sticas gerais
SELECT * FROM get_documents_stats();
```

**Valida√ß√µes**:
- [ ] Total de chunks >= 50
- [ ] 5 categorias "servicos" presentes
- [ ] 5 arquivos fonte presentes
- [ ] Todos os embeddings n√£o s√£o NULL
- [ ] avg_content_length razo√°vel (500-1000 chars)

**Resultado**: PENDENTE

---

### Teste 3: Importar Workflow n8n

**Passos**:
1. Acessar n8n (http://localhost:5678)
2. Workflows ‚Üí Import from File
3. Selecionar `n8n/workflows/03_rag_knowledge_query.json`
4. Configurar credenciais:
   - OpenAI API (id: openai-embeddings)
   - PostgreSQL Supabase (id: supabase-postgres)
5. Ativar workflow

**Valida√ß√µes**:
- [ ] Workflow importado sem erros
- [ ] Todos os n√≥s vis√≠veis e conectados
- [ ] Credenciais configuradas
- [ ] Webhook URL dispon√≠vel

**Resultado**: PENDENTE

---

### Teste 4: Query RAG - "como funciona energia solar"

**Request**:
```bash
curl -X POST http://localhost:5678/webhook/rag-query \
  -H "Content-Type: application/json" \
  -d '{
    "query_text": "como funciona energia solar"
  }'
```

**Valida√ß√µes**:
- [ ] Response HTTP 200
- [ ] success: true
- [ ] results array com 3-5 itens
- [ ] Cada result tem: rank, content, source, similarity, relevance
- [ ] source.file cont√©m "energia_solar.md"
- [ ] source.category = "servicos"
- [ ] similarity >= 0.75 (75%)
- [ ] relevance = "high" ou "medium"
- [ ] context string formatado para AI
- [ ] metadata.total_results >= 3
- [ ] metadata.average_similarity >= 0.75

**Resultado**: PENDENTE

---

### Teste 5: Query RAG - Com Filtro de Categoria

**Request**:
```bash
curl -X POST http://localhost:5678/webhook/rag-query \
  -H "Content-Type: application/json" \
  -d '{
    "query_text": "quanto custa",
    "category": "servicos",
    "match_count": 10
  }'
```

**Valida√ß√µes**:
- [ ] Retorna at√© 10 resultados
- [ ] Todos de category "servicos"
- [ ] Busca em m√∫ltiplos arquivos
- [ ] metadata.category_filter = "servicos"

**Resultado**: PENDENTE

---

### Teste 6: Query RAG - Cada Servi√ßo

**Queries de Teste**:
1. "energia solar residencial" ‚Üí deve retornar chunks de energia_solar.md
2. "subesta√ß√£o transformador" ‚Üí deve retornar chunks de subestacao.md
3. "projeto el√©trico residencial" ‚Üí deve retornar chunks de projetos_eletricos.md
4. "bateria l√≠tio armazenamento" ‚Üí deve retornar chunks de armazenamento_energia.md
5. "an√°lise de consumo energ√©tico" ‚Üí deve retornar chunks de analise_laudos.md

**Valida√ß√µes**:
- [ ] Todos os 5 servi√ßos retornam resultados relevantes
- [ ] Similarity score adequado (>= 0.75)
- [ ] Context string √∫til para AI

**Resultado**: PENDENTE

---

### Teste 7: Performance - Tempo de Resposta

**Comando**:
```bash
time curl -X POST http://localhost:5678/webhook/rag-query \
  -H "Content-Type: application/json" \
  -d '{"query_text": "teste performance"}'
```

**Valida√ß√µes**:
- [ ] Tempo total < 2 segundos
- [ ] Query Supabase < 500ms (verificar com EXPLAIN ANALYZE)
- [ ] OpenAI embedding generation < 1 segundo

**Resultado**: PENDENTE

---

### Teste 8: Performance - Query Database

**Query SQL**:
```sql
EXPLAIN ANALYZE
SELECT * FROM match_documents(
    (SELECT embedding FROM knowledge_documents LIMIT 1),
    0.75,
    5,
    NULL
);
```

**Valida√ß√µes**:
- [ ] Execution Time < 500ms
- [ ] Usa ivfflat index (verificar no plan)
- [ ] N√£o faz seq scan completo

**Resultado**: PENDENTE

---

### Teste 9: Error Handling - Sem query_text

**Request**:
```bash
curl -X POST http://localhost:5678/webhook/rag-query \
  -H "Content-Type: application/json" \
  -d '{}'
```

**Valida√ß√µes**:
- [ ] Response HTTP 400
- [ ] Body cont√©m: { "error": "query_text is required", "status": "error" }

**Resultado**: PENDENTE

---

### Teste 10: Error Handling - Nenhum Resultado

**Request**:
```bash
curl -X POST http://localhost:5678/webhook/rag-query \
  -H "Content-Type: application/json" \
  -d '{
    "query_text": "xyzabcqwerty123",
    "match_threshold": 0.95
  }'
```

**Valida√ß√µes**:
- [ ] Response HTTP 200
- [ ] success: false
- [ ] results: []
- [ ] context: ""
- [ ] message: "Nenhum conhecimento relevante encontrado"

**Resultado**: PENDENTE

---

## ‚úÖ Crit√©rios de Aceita√ß√£o Final

**Sprint 1.1 ser√° APROVADO se**:

1. ‚úÖ Todos os 5 arquivos de conhecimento completos e estruturados
2. ‚è≥ Script de ingest executa sem erros e popula Supabase
3. ‚è≥ Workflow n8n funciona e retorna resultados relevantes
4. ‚è≥ Query "como funciona energia solar" retorna 3-5 resultados com >75% similarity
5. ‚è≥ Todos os 5 servi√ßos podem ser consultados via RAG
6. ‚è≥ Performance adequada (<500ms query DB, <2s total)
7. ‚è≥ Error handling funciona corretamente

**Pr√≥ximos Passos Ap√≥s Aprova√ß√£o**:
- Sprint 1.2: Sistema de Agendamento Completo
- Sprint 1.3: Sistema de Notifica√ß√µes por Email
- Sprint 1.4: Sincroniza√ß√£o CRM Bidirecional
- Sprint 1.5: Handoff para Humanos

---

## üìù Notas de Implementa√ß√£o

### Decis√µes T√©cnicas

1. **Modelo de Embeddings**: text-embedding-3-small (1536 dims)
   - Raz√£o: Balance custo/qualidade, compat√≠vel com Supabase vector
   - Alternativa considerada: ada-002 (deprecated)

2. **Similarity Threshold**: 0.75 (75%)
   - Raz√£o: Balance qualidade vs. recall
   - Pode ser ajustado via par√¢metro na query

3. **Chunk Size**: 500-1000 caracteres com overlap 100
   - Raz√£o: Contexto suficiente sem perder granularidade
   - Respeita quebras naturais em markdown (##)

4. **√çndice ivfflat**: lists=100
   - Raz√£o: Otimizado para dataset pequeno (<10K vetores)
   - Ajustar para lists=sqrt(total_rows) se crescer

5. **Tabela knowledge_documents**:
   - Renomeado de knowledge_base para maior clareza
   - Adicionado source_file para rastreabilidade
   - Category simplificado (VARCHAR vs JSONB) para performance

### Pontos de Aten√ß√£o

- **Custo OpenAI**: ~$0.0001 por 1K tokens ‚Üí estimativa $0.10 total ingest
- **Supabase Storage**: ~50-100 chunks √ó 1536 dims √ó 4 bytes = ~300KB embeddings
- **Re-ingest**: Usar delete_documents_by_category() antes de re-processar
- **Updates**: Usar delete_documents_by_source() para atualizar arquivo espec√≠fico

### Troubleshooting Comum

**Problema**: "pgvector extension not found"
**Solu√ß√£o**: Executar `CREATE EXTENSION IF NOT EXISTS vector;` no Supabase

**Problema**: Ingest script falha com erro OpenAI
**Solu√ß√£o**: Verificar OPENAI_API_KEY est√° configurada e tem cr√©ditos

**Problema**: Queries muito lentas
**Solu√ß√£o**:
1. Verificar √≠ndice ivfflat foi criado
2. Aumentar shared_buffers no PostgreSQL
3. Verificar lists parameter do √≠ndice

**Problema**: Resultados irrelevantes
**Solu√ß√£o**:
1. Reduzir match_threshold (ex: 0.70)
2. Aumentar match_count (ex: 10)
3. Melhorar conte√∫do dos documentos

---

**Documento criado**: 2025-01-12
**√öltima atualiza√ß√£o**: 2025-01-12
**Status**: Aguardando execu√ß√£o dos testes
